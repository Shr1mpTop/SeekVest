import os
import pandas as pd
import configparser
from openai import OpenAI
from pathlib import Path
import concurrent.futures
from tqdm import tqdm


def load_config():
    config = configparser.ConfigParser()
    config.read('stock_crawler/config.ini')
    return config


def analyze_batch(batch_df, batch_num, config, batch_size, top_n):
    client = OpenAI(
        api_key=config['LLM']['api_key'],
        base_url=config['LLM']['base_url']
    )
    # ç”Ÿæˆè‚¡ç¥¨åˆ—è¡¨
    stock_list = "\n".join([f"{idx + 1}. {row['ä»£ç ']} {row['åç§°']}"
                            for idx, row in batch_df.head(top_n).iterrows()])

    prompt = f"""è¯·ä¸¥æ ¼æŒ‰ä»¥ä¸‹è¦æ±‚åˆ†æç¬¬{batch_num}æ‰¹è‚¡ç¥¨æ•°æ®ï¼ˆå…±{len(batch_df)}åªï¼‰ï¼š
1. ä»ä»¥ä¸‹ç»´åº¦è¯„ä¼°ï¼š
   - çŸ­æœŸè¶‹åŠ¿ï¼ˆ3æ—¥/5æ—¥æ¶¨è·Œå¹…ï¼‰
   - é‡èƒ½å˜åŒ–ï¼ˆå¯¹æ¯”20æ—¥æˆäº¤é‡å‡å€¼ï¼‰
   - ä¼°å€¼æ°´å¹³ï¼ˆè¡Œä¸šPE/PBåˆ†ä½å€¼ï¼‰
   - èµ„é‡‘çƒ­åº¦ï¼ˆæ¢æ‰‹ç‡åŠé‡æ¯”ï¼‰
   - æŠ€æœ¯å½¢æ€ï¼ˆå…³é”®æ”¯æ’‘/å‹åŠ›ä½ï¼‰

2. ä¼˜è´¨æ ‡çš„ï¼ˆå‰{top_n}ï¼‰ï¼š
{stock_list}

3. åˆ†æè¦æ±‚ï¼š
   â˜…æ ¸å¿ƒä¼˜åŠ¿ï¼ˆ35å­—å…³é”®æŒ‡æ ‡ï¼‰
   âš ï¸ä¸»è¦é£é™©ï¼ˆ20å­—æ˜ç¡®é£é™©ç‚¹ï¼‰

è‚¡ç¥¨æ•°æ®ï¼š
{batch_df.to_csv(index=False)}

è¯·æŒ‰æ ¼å¼è¿”å›ï¼š
ã€ç¬¬{batch_num}æ‰¹ä¼˜é€‰ã€‘
1. ä»£ç  åç§°
   â˜…ä¼˜åŠ¿: ...
   âš ï¸é£é™©: ..."""

    try:
        response = client.chat.completions.create(
            model=config['LLM']['model'],
            messages=[{"role": "user", "content": prompt}],
            temperature=0.2,
            timeout=300
        )
        result = response.choices[0].message.content.strip()
        if not result or "ä¼˜é€‰" not in result:
            raise ValueError("å¤§æ¨¡å‹è¿”å›æ ¼å¼å¼‚å¸¸")
        return result
    except Exception as e:
        print(f"âš ï¸ ç¬¬{batch_num}æ‰¹åˆ†æå¼‚å¸¸: {str(e)}")
        return f"ã€ç¬¬{batch_num}æ‰¹å¼‚å¸¸ã€‘{str(e)}"


def analyze_file(excel_file, config, batch_size=200, top_n=3):
    try:
        df = pd.read_excel(excel_file)

        # æ•°æ®æœ‰æ•ˆæ€§æ£€æŸ¥
        required_columns = ['ä»£ç ', 'åç§°', 'æ¶¨è·Œå¹…', 'æˆäº¤é‡ï¼ˆæ‰‹ï¼‰', 'å¸‚ç›ˆç‡(åŠ¨æ€)', 'å¸‚å‡€ç‡']
        if not all(col in df.columns for col in required_columns):
            raise ValueError("æ–‡ä»¶ç¼ºå°‘å¿…è¦åˆ—")

        if df.empty or df['ä»£ç '].isnull().all():
            raise ValueError("æ•°æ®æ— æ•ˆ")

        batch_results = []
        total_batches = (len(df) + batch_size - 1) // batch_size
        with concurrent.futures.ThreadPoolExecutor() as executor:
            futures = []
            # åˆ†æ‰¹æ¬¡å¤„ç†æ•°æ®
            for i in range(0, len(df), batch_size):
                batch_df = df.iloc[i:i + batch_size]
                batch_num = i // batch_size + 1
                future = executor.submit(analyze_batch, batch_df, batch_num, config, batch_size, top_n)
                futures.append(future)

            # è·å–æ‰€æœ‰çº¿ç¨‹çš„ç»“æœ
            for future in concurrent.futures.as_completed(futures):
                result = future.result()
                batch_results.append(result)

        # æå–å„æ‰¹æ¬¡ä¼˜é€‰è‚¡ç¥¨çš„ä»£ç 
        selected_stock_codes = []
        for result in batch_results:
            if "ä¼˜é€‰" in result:
                lines = result.split('\n')
                for line in lines:
                    if line.strip().startswith('1. '):
                        code = line.split(' ')[1]
                        selected_stock_codes.append(code)

        # ç­›é€‰å‡ºä¼˜é€‰è‚¡ç¥¨çš„æ•°æ®
        selected_df = df[df['ä»£ç '].isin(selected_stock_codes)]

        return selected_df, batch_results
    except Exception as e:
        print(f"\nâš ï¸ åˆ†æå¤±è´¥: {str(e)}")
        return None, []


def process_all_files():
    data_dir = Path('data')
    config = load_config()
    all_dfs = []
    all_batch_results = []
    excel_files = list(data_dir.glob('*.xlsx'))
    with concurrent.futures.ThreadPoolExecutor() as executor:
        futures = []
        for excel_file in excel_files:
            future = executor.submit(analyze_file, excel_file, config)
            futures.append(future)

        # ä½¿ç”¨ tqdm æ˜¾ç¤ºè¿›åº¦æ¡
        with tqdm(total=len(futures), desc="åˆ†æè¿›åº¦") as pbar:
            for future in concurrent.futures.as_completed(futures):
                df, batch_results = future.result()
                if df is not None:
                    all_dfs.append(df)
                    all_batch_results.extend(batch_results)
                pbar.update(1)

    # åˆå¹¶æ‰€æœ‰ä¼˜é€‰è‚¡ç¥¨çš„åŸå§‹æ•°æ®
    all_data = pd.concat(all_dfs, ignore_index=True)

    # æœ€ç»ˆæ±‡æ€»åˆ†æ
    final_prompt = f"""è¯·ä»å„æ‰¹æ¬¡ä¼˜é€‰è‚¡ç¥¨ä¸­è¯„é€‰æœ€ç»ˆå‰3åï¼š

{chr(10).join(all_batch_results)}

ä»¥ä¸‹æ˜¯å„æ‰¹æ¬¡ä¼˜é€‰è‚¡ç¥¨çš„åŸå§‹æ•°æ®ï¼š
{all_data.to_csv(sep=chr(9), na_rep='nan')}

è¯„é€‰æ ‡å‡†ï¼š
1. æŠ€æœ¯é¢ï¼ˆé‡ä»·é…åˆã€è¶‹åŠ¿å½¢æ€ï¼‰40%
2. åŸºæœ¬é¢ï¼ˆä¼°å€¼åˆç†æ€§ï¼‰30%
3. å¸‚åœºå…³æ³¨åº¦ï¼ˆæˆäº¤é‡ï¼‰20%
4. é£é™©æ”¶ç›Šæ¯” 10%

è¯·ç”¨ä»¥ä¸‹æ ¼å¼è¿”å›ï¼š
ğŸ† ä»Šæ—¥ç»ˆæä¼˜é€‰ï¼š
ğŸ¥‡ [ä»£ç ] [åç§°] - æ ¸å¿ƒäº®ç‚¹+é£é™©æç¤º
ğŸ¥ˆ [ä»£ç ] [åç§°] - æ ¸å¿ƒäº®ç‚¹+é£é™©æç¤º
ğŸ¥‰ [ä»£ç ] [åç§°] - æ ¸å¿ƒäº®ç‚¹+é£é™©æç¤º"""

    client = OpenAI(
        api_key=config['LLM']['api_key'],
        base_url=config['LLM']['base_url']
    )
    final_response = client.chat.completions.create(
        model=config['LLM']['model'],
        messages=[{"role": "user", "content": final_prompt}],
        temperature=0.2
    )

    results = [f"# æœ€ç»ˆåˆ†æ\n{final_response.choices[0].message.content}\nâ€» æ•°æ®æ¥æºï¼š{len(all_batch_results) * 3}åªå€™é€‰è‚¡"]

    with open('stock_analysis_report.md', 'w') as f:
        f.write("# æ¯æ—¥è‚¡ç¥¨æ½œåŠ›åˆ†ææŠ¥å‘Š\n\n" + "\n\n".join(results))


if __name__ == "__main__":
    process_all_files()
    print("åˆ†æå®Œæˆï¼ç»“æœå·²ä¿å­˜è‡³ stock_analysis_report.md")